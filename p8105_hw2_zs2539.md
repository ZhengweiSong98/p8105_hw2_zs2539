p8105_hw2_zs2539
================
Zhengwei Song
2022-10-03

# Problem 1 Solution

### Importing data tables

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
NYC_transit_data_raw = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
            col_types = cols(
    Route8 = col_character(),
    Route9 = col_character(),
    Route10 = col_character(),
    Route11 = col_character()
        ))
```

### Cleaning up variable names

``` r
names(NYC_transit_data_raw)
```

    ##  [1] "Division"           "Line"               "Station Name"      
    ##  [4] "Station Latitude"   "Station Longitude"  "Route1"            
    ##  [7] "Route2"             "Route3"             "Route4"            
    ## [10] "Route5"             "Route6"             "Route7"            
    ## [13] "Route8"             "Route9"             "Route10"           
    ## [16] "Route11"            "Entrance Type"      "Entry"             
    ## [19] "Exit Only"          "Vending"            "Staffing"          
    ## [22] "Staff Hours"        "ADA"                "ADA Notes"         
    ## [25] "Free Crossover"     "North South Street" "East West Street"  
    ## [28] "Corner"             "Entrance Latitude"  "Entrance Longitude"
    ## [31] "Station Location"   "Entrance Location"

``` r
NYC_transit_data_clean_names = janitor::clean_names(NYC_transit_data_raw)
names(NYC_transit_data_clean_names)
```

    ##  [1] "division"           "line"               "station_name"      
    ##  [4] "station_latitude"   "station_longitude"  "route1"            
    ##  [7] "route2"             "route3"             "route4"            
    ## [10] "route5"             "route6"             "route7"            
    ## [13] "route8"             "route9"             "route10"           
    ## [16] "route11"            "entrance_type"      "entry"             
    ## [19] "exit_only"          "vending"            "staffing"          
    ## [22] "staff_hours"        "ada"                "ada_notes"         
    ## [25] "free_crossover"     "north_south_street" "east_west_street"  
    ## [28] "corner"             "entrance_latitude"  "entrance_longitude"
    ## [31] "station_location"   "entrance_location"

### Selecting required columns in problem 1

``` r
library(dplyr)
NYC_transit_data_selected_cols = select(NYC_transit_data_clean_names, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada)
```

### Combining routes columns

``` r
NYC_transit_data_combined_cols = 
  pivot_longer(
    NYC_transit_data_selected_cols, 
    route1:route11,
    names_to = NULL,
    values_to = "route_number",
    values_drop_na = TRUE)
```

### Converting to Logical variables for entry and vending

``` r
NYC_transit_data_logical_cols = mutate(NYC_transit_data_combined_cols,
    entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"),
    entry = as.logical(entry),
    vending = recode(vending, "YES" = "TRUE", "NO" = "FALSE"),
    vending = as.logical(vending),
    )
```

### Selecting distinct rows of the dataset

``` r
NYC_transit_data_final = NYC_transit_data_logical_cols %>% distinct()
```

### Summary

This has read and cleaned the data as required, and the whole process is
shown above. The resulting dataset is 1559 rows x 9 columns, including
line, station name, station latitude / longitude, routes served, entry,
vending, entrance type and ADA compliance.

``` r
tail(NYC_transit_data_final)
```

    ## # A tibble: 6 × 9
    ##   line              statio…¹ stati…² stati…³ entry vending entra…⁴ ada   route…⁵
    ##   <chr>             <chr>      <dbl>   <dbl> <lgl> <lgl>   <chr>   <lgl> <chr>  
    ## 1 White Plains Road Simpson…    40.8   -73.9 TRUE  TRUE    Stair   TRUE  2      
    ## 2 White Plains Road Simpson…    40.8   -73.9 TRUE  TRUE    Stair   TRUE  5      
    ## 3 White Plains Road Wakefie…    40.9   -73.9 TRUE  TRUE    Stair   FALSE 2      
    ## 4 White Plains Road Wakefie…    40.9   -73.9 TRUE  TRUE    Stair   FALSE 5      
    ## 5 Flushing          34 St H…    40.8   -74.0 TRUE  TRUE    Elevat… TRUE  7      
    ## 6 Flushing          34 St H…    40.8   -74.0 TRUE  TRUE    Stair   TRUE  7      
    ## # … with abbreviated variable names ¹​station_name, ²​station_latitude,
    ## #   ³​station_longitude, ⁴​entrance_type, ⁵​route_number

## Answering Questions in problem 1

### It has 356 distinct stations in total by the coding below

``` r
NYC_transit_data_final %>% distinct(station_name) %>% count()
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1   356

### Similarly, 73 stations are ADA compliant

``` r
NYC_transit_data_final %>% filter(ada == "TRUE") %>% distinct(station_name) %>% count()
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    73

### 60.38% station entrances / exits without vending allow entrance

``` r
a = NYC_transit_data_final %>% filter(vending == "FALSE", entry == "FALSE") %>% select(station_name, entry) %>% distinct() %>% count()

b = NYC_transit_data_final %>% filter(vending == "FALSE") %>% select(station_name, entry) %>% distinct() %>% count()

a/b
```

    ##           n
    ## 1 0.6037736

### 56 stations serve A train, and 16 of them are ADA compliant

``` r
NYC_transit_data_final %>% select(station_name, route_number) %>% filter(route_number == "A") %>% distinct(station_name) %>% count()
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    56

``` r
NYC_transit_data_final %>% select(station_name, route_number, ada) %>% filter(route_number == "A", ada == "TRUE") %>% distinct(station_name) %>% count()
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    16

# Problem 2 Solution

### Importing data table Mr. Trash Wheel

``` r
library(readxl)
Trash_wheel_mr = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = 'Mr. Trash Wheel', range = 'A2:N534') %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

### Importing data table Professor Trash Wheel

``` r
Trash_wheel_prof = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = 'Professor Trash Wheel', range = 'A2:N116') %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

### Combining

``` r
Trash_wheel_comb = bind_rows(Trash_wheel_mr, Trash_wheel_prof, .id = "trash_wheel")
```

### Summary

``` r
a = Trash_wheel_comb %>% count()
b = Trash_wheel_comb %>% filter(trash_wheel == "1") %>% count()
c = a-b

d = ncol(Trash_wheel_comb)

e = sum(Trash_wheel_comb$weight_tons)
f = Trash_wheel_comb %>% filter(trash_wheel == "1") %>% summarize(sum(weight_tons))
j = e-f

h = sum(Trash_wheel_comb$cigarette_butts) 
g = as.integer(h/nrow(Trash_wheel_comb))

i = Trash_wheel_comb %>% filter(trash_wheel == "1", year == "2020") %>% summarize(sum(sports_balls))
```

The Mr. Trash Wheel and the Professional Trash Wheel are two trash
wheels used to clear trash and debris from the Inner Harbor of
Baltimore, Maryland. These two datasets describe the amount and type of
garbage collected by bins and dates. The dataset includes 524
observations, including 71 for the Mr. Trash Wheel and 453 for the
Professional Trash Wheel, with each observation representing a collected
bin. The 15 column variables include the weight, volume, and type of
waste, as well as estimates of households using incineration to generate
electricity such as `weight_tons`, `volume_cubic_yards`,
`plastic_bottles`, `cigarette_butts` et al. From May 2014 to January
2021, the two Trash Wheels collected a total of 1585.2 tons of garbage,
of which Mr. Trash Wheel dominated with 1449.7 tons, and Professor Trash
Wheel shared 135.5 tons. In detail, in 2020, Mr. Trash Wheel collected
856 sport balls. Also, cigarette butt was a common pollution item in the
port. Each bin collected 23118 cigarette butts on average, and a total
of 12114198 cigarette butts were collected during the period.

# Problem 3 Solution

### Importing and cleaning pols-month dataset

``` r
pols_month = read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
    janitor::clean_names() %>% 
    separate(col = mon, into = c("year", "month", "day")) %>% 
    mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day), month = month.name[month], president = recode(prez_dem, `1` = "dem", `0` = "gop")) %>% 
    select(-prez_gop, -prez_dem, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Importing and cleaning snp dataset

``` r
snp_data = read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>%
    janitor::clean_names() %>%
    separate(col = date, into = c("year", "month", "day")) %>% 
    mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day), month = month.name[month]) %>% 
    select(-day)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (1): close
    ## date (1): date
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Importing and cleaning unemployment dataset

``` r
unemployment_data = read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>%
    janitor::clean_names() %>% 
    pivot_longer(
    jan:dec, names_to = "month", values_to = "percentage") %>% 
    mutate(month = recode(month, "jan" = "January", 
                   "feb" = "February", 
                   "mar" = "March", 
                   "apr" = "April", 
                   "may" = "May", 
                   "jun" = "June", 
                   "jul" = "July", 
                   "aug" = "August", 
                   "sep" = "September", 
                   "oct" = "October", 
                   "nov" = "November", 
                   "dec" = "December")) %>%
    select(everything())
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Merging by `left_join`

``` r
pols_snp_merge = 
  left_join(pols_month, snp_data, by = c("year","month"))

merge_final = 
  left_join(pols_snp_merge, unemployment_data, by = c("year","month"))
```

### Summary

`pols_month` contains 9 variables and 822 observations, describing the
respective numbers of presidents, governors, senators, and party
representatives in Republicans and Democrats in certain date from
January 1947 to January 2015.

`snp_data` contains 3 variables and 787 observations, describing the
closing values of the S&P stock index on the associated date from
January 1950 to July 2015.

`unemployment_data` contains 3 variables and 816 observations,
describing the percentage of unemployment in months of the associated
year from January 1948 to December 2015.

The final dataset `merge_final` is a merge of the above three datasets
by year and month containing 11 variables and 822 observations. This
will allow further comparison of presidential party power with
socioeconomic outcomes such as unemployment and stocks.
